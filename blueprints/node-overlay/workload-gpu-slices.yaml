# Sample workload requesting a GPU slice (1/4 of a GPU)
#
# This deployment requests nvidia.com/gpu: 1. With time-slicing configured
# on the EC2NodeClass (replicas = 4), the node advertises nvidia.com/gpu: 4
# for a single physical GPU. This means 4 pods can share one GPU instance.
#
# The NodeOverlay tells Karpenter about this capacity BEFORE provisioning,
# enabling better scheduling decisions and consolidation.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: workload-gpu-slices
spec:
  replicas: 4
  selector:
    matchLabels:
      app: workload-gpu-slices
  template:
    metadata:
      labels:
        app: workload-gpu-slices
    spec:
      nodeSelector:
        intent: gpu-workloads
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      containers:
      - name: gpu-workload
        image: public.ecr.aws/eks-distro/kubernetes/pause:v1.33.0-eks-1-33-4
        imagePullPolicy: Always
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            nvidia.com/gpu: 1
